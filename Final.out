\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Overview of the thesis}{chapter.1}% 2
\BOOKMARK [0][-]{chapter.2}{Background}{}% 3
\BOOKMARK [1][-]{section.2.1}{Neural networks}{chapter.2}% 4
\BOOKMARK [2][-]{subsection.2.1.1}{Feedforward neural networks}{section.2.1}% 5
\BOOKMARK [2][-]{subsection.2.1.2}{Error functions}{section.2.1}% 6
\BOOKMARK [2][-]{subsection.2.1.3}{Training neural networks}{section.2.1}% 7
\BOOKMARK [2][-]{subsection.2.1.4}{Convolutional neural networks \(CNNs\)}{section.2.1}% 8
\BOOKMARK [2][-]{subsection.2.1.5}{Recurrent neural networks \(RNNs\)}{section.2.1}% 9
\BOOKMARK [2][-]{subsection.2.1.6}{Long short-term memory \(LSTM\)}{section.2.1}% 10
\BOOKMARK [2][-]{subsection.2.1.7}{Training of RNNs}{section.2.1}% 11
\BOOKMARK [1][-]{section.2.2}{Word embedding}{chapter.2}% 12
\BOOKMARK [2][-]{subsection.2.2.1}{Skip-gram embedding model}{section.2.2}% 13
\BOOKMARK [1][-]{section.2.3}{Jointly learn image and word}{chapter.2}% 14
\BOOKMARK [1][-]{section.2.4}{Image-based question answering}{chapter.2}% 15
\BOOKMARK [2][-]{subsection.2.4.1}{DAQUAR dataset}{section.2.4}% 16
\BOOKMARK [2][-]{subsection.2.4.2}{Previous attempt}{section.2.4}% 17
\BOOKMARK [0][-]{chapter.3}{Methods and Results}{}% 18
\BOOKMARK [1][-]{section.3.1}{Problem restatement}{chapter.3}% 19
\BOOKMARK [1][-]{section.3.2}{Our models}{chapter.3}% 20
\BOOKMARK [2][-]{subsection.3.2.1}{GUESS model}{section.3.2}% 21
\BOOKMARK [2][-]{subsection.3.2.2}{BOW model}{section.3.2}% 22
\BOOKMARK [2][-]{subsection.3.2.3}{LSTM sentence model}{section.3.2}% 23
\BOOKMARK [2][-]{subsection.3.2.4}{Image-word model}{section.3.2}% 24
\BOOKMARK [2][-]{subsection.3.2.5}{Bidirectional image-word model}{section.3.2}% 25
\BOOKMARK [2][-]{subsection.3.2.6}{Image-word ranking model}{section.3.2}% 26
\BOOKMARK [2][-]{subsection.3.2.7}{DAQUAR results}{section.3.2}% 27
\BOOKMARK [1][-]{section.3.3}{COCO-QA dataset}{chapter.3}% 28
\BOOKMARK [2][-]{subsection.3.3.1}{Question conversion algorithms}{section.3.3}% 29
\BOOKMARK [2][-]{subsection.3.3.2}{Reducing rare answers}{section.3.3}% 30
\BOOKMARK [2][-]{subsection.3.3.3}{Reducing common answers}{section.3.3}% 31
\BOOKMARK [2][-]{subsection.3.3.4}{Question statistics}{section.3.3}% 32
\BOOKMARK [2][-]{subsection.3.3.5}{Question quality}{section.3.3}% 33
\BOOKMARK [2][-]{subsection.3.3.6}{Learning results}{section.3.3}% 34
\BOOKMARK [0][-]{chapter.4}{Discussion}{}% 35
\BOOKMARK [1][-]{section.4.1}{Model selection}{chapter.4}% 36
\BOOKMARK [2][-]{subsection.4.1.1}{LSTM sentence model}{section.4.1}% 37
\BOOKMARK [2][-]{subsection.4.1.2}{Word embedding}{section.4.1}% 38
\BOOKMARK [2][-]{subsection.4.1.3}{Single direction or bi-direction}{section.4.1}% 39
\BOOKMARK [2][-]{subsection.4.1.4}{Softmax cross entropy or ranking loss}{section.4.1}% 40
\BOOKMARK [1][-]{section.4.2}{Dataset selection}{chapter.4}% 41
\BOOKMARK [1][-]{section.4.3}{Visual and semantic knowledge}{chapter.4}% 42
\BOOKMARK [0][-]{chapter.5}{Future Work}{}% 43
\BOOKMARK [1][-]{section.5.1}{Exploration of current models}{chapter.5}% 44
\BOOKMARK [1][-]{section.5.2}{Visual attention model}{chapter.5}% 45
\BOOKMARK [1][-]{section.5.3}{Better question generation algorithms}{chapter.5}% 46
\BOOKMARK [1][-]{section.5.4}{Longer answers and free-form answers}{chapter.5}% 47
\BOOKMARK [0][-]{chapter.6}{Conclusion}{}% 48
\BOOKMARK [0][-]{appendix.A}{Neural networks training techniques}{}% 49
\BOOKMARK [1][-]{section.A.1}{Momentum}{appendix.A}% 50
\BOOKMARK [1][-]{section.A.2}{Weight regularization}{appendix.A}% 51
\BOOKMARK [1][-]{section.A.3}{Dropout}{appendix.A}% 52
\BOOKMARK [1][-]{section.A.4}{Gradient control in training RNNs}{appendix.A}% 53
\BOOKMARK [2][-]{subsection.A.4.1}{Gradient clipping}{section.A.4}% 54
\BOOKMARK [2][-]{subsection.A.4.2}{Weight clipping}{section.A.4}% 55
\BOOKMARK [1][-]{section.A.5}{Dropout in RNNs}{appendix.A}% 56
\BOOKMARK [0][-]{appendix.B}{Model training details}{}% 57
\BOOKMARK [1][-]{section.B.1}{Image-word model}{appendix.B}% 58
\BOOKMARK [1][-]{section.B.2}{Blind model}{appendix.B}% 59
\BOOKMARK [1][-]{section.B.3}{Image-word ranking model}{appendix.B}% 60
\BOOKMARK [1][-]{section.B.4}{Bidirectional model}{appendix.B}% 61
