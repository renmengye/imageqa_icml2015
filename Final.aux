\relax 
\citation{simonyan14}
\citation{krizhevsky12}
\citation{sutskever14}
\citation{kiros14b}
\citation{malinowski14b}
\citation{malinowski14b}
\citation{mscoco}
\citation{ffnn}
\citation{cnn}
\citation{krizhevsky12}
\citation{simonyan14}
\citation{krizhevsky12}
\citation{sutskever14}
\citation{kiros14b}
\citation{malinowski14a}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Overview of the thesis}{4}}
\citation{krizhevsky12}
\citation{girshick14}
\citation{dahl12}
\citation{deng13}
\citation{mnih07}
\citation{mikolov10}
\citation{hassoun03}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{background}{{2}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Neural networks}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces An artificial neuron\relax }}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:neuron}{{2.1}{5}}
\citation{du2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The sigmoid function\relax }}{6}}
\newlabel{fig:sigmoid}{{2.2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Feedforward neural networks}{6}}
\citation{ffnn}
\citation{ffnn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A feedforward net with one hidden layer (adapted from \cite  {ffnn})\relax }}{7}}
\newlabel{fig:ffnet}{{2.3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Error functions}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Training neural networks}{8}}
\citation{lecun98}
\citation{lecun98}
\citation{lecun98}
\citation{cnn}
\citation{cnn}
\citation{krizhevsky12}
\citation{krizhevsky12}
\citation{krizhevsky12}
\citation{girshick14}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces A convolutional neural net \cite  {cnn}\relax }}{9}}
\newlabel{fig:cnn}{{2.4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Convolutional neural networks (CNNs)}{9}}
\citation{hochreiter97}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Automatically learned low-level image filters \cite  {krizhevsky12}\relax }}{10}}
\newlabel{fig:cnn_filters}{{2.5}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A recurrent neuron with a feedback loop\relax }}{10}}
\newlabel{fig:rnn}{{2.6}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Recurrent neural networks (RNNs)}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Long short-term memory (LSTM)}{10}}
\citation{mozer95}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Long short-term memory\relax }}{11}}
\newlabel{fig:lstm}{{2.7}{11}}
\newlabel{eq:lstm}{{2.11}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.7}Training of RNNs}{11}}
\citation{zipf49}
\citation{bengio03}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Back-propagation through time\relax }}{12}}
\newlabel{fig:bptt}{{2.8}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Word embedding}{12}}
\citation{mikolov13}
\citation{mikolov13}
\citation{frome13}
\citation{weston10}
\citation{krizhevsky12}
\citation{mikolov13}
\citation{kiros14b}
\citation{kulkarni11}
\citation{mitchell12}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Skip-gram embedding model}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Jointly learn image and word}{13}}
\citation{lewis12}
\citation{weston14}
\citation{malinowski14a}
\citation{silberman12}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Image-based question answering}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}DAQUAR dataset}{14}}
\newlabel{background_daquar}{{2.4.1}{14}}
\citation{malinowski14b}
\citation{liang13}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Various types of difficult questions in the DAQUAR dataset\relax }}{15}}
\newlabel{fig:difficult}{{2.9}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Previous attempt}{16}}
\citation{simonyan14}
\citation{sutskever14}
\citation{bleu}
\citation{luong14}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods and Results}{17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem restatement}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Our models}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}GUESS model}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}BOW model}{17}}
\citation{vinyals14}
\citation{simonyan14}
\citation{mikolov13}
\citation{frome13}
\citation{wu94}
\citation{malinowski14b}
\citation{malinowski14b}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}LSTM sentence model}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Image-word model}{18}}
\citation{weston10}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Image-word model and blind model\relax }}{19}}
\newlabel{fig:imgword}{{3.1}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Bidirectional image-word model}{19}}
\citation{kiros14b}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Bidirectional image-word model and blind model\relax }}{20}}
\newlabel{fig:imgword}{{3.2}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}Image-word ranking model}{20}}
\citation{malinowski14b}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Direct comparison between the image-word model and the blind model.\relax }}{21}}
\newlabel{fig:imgword+blind}{{3.3}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.7}DAQUAR results}{21}}
\newlabel{sec:daquar_results}{{3.2.7}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}COCO-QA dataset}{21}}
\citation{mscoco}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces DAQUAR results\relax }}{22}}
\newlabel{tab:daquar_results}{{3.1}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Question conversion algorithms}{22}}
\@writefile{toc}{\contentsline {subsubsection}{Object-type questions}{22}}
\citation{borsley99}
\citation{chomsky73}
\citation{wordnet}
\citation{nltk}
\citation{klein03}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Split compound sentences\relax }}{24}}
\newlabel{alg:splitcc}{{1}{24}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Replace indefinite determiners to definite determiners\relax }}{24}}
\newlabel{alg:indef2def}{{2}{24}}
\@writefile{toc}{\contentsline {subsubsection}{Number-type questions}{24}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Identify object-type answers\relax }}{25}}
\newlabel{alg:traverseWhat}{{3}{25}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Wh-movement\relax }}{25}}
\newlabel{alg:whmove}{{4}{25}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Generate object-type questions\relax }}{26}}
\newlabel{alg:askWhat}{{5}{26}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Identify number-type answers\relax }}{26}}
\newlabel{alg:traverseHowMany}{{6}{26}}
\@writefile{toc}{\contentsline {subsubsection}{Colour-type questions}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Reducing rare answers}{26}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Generate number-type questions\relax }}{27}}
\newlabel{alg:askHowMany}{{7}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Reducing common answers}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Question statistics}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces General statistics of COCO-QA and DAQUAR\relax }}{28}}
\newlabel{tab:cocoqa_stats}{{3.2}{28}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces  COCO-QA and DAQUAR question type break-down (numbers inside the brackets denote the proportion with regard to the entire dataset)\relax }}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}Question quality}{28}}
\citation{ilsvrc14}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.6}Learning results}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces COCO-QA results\relax }}{29}}
\newlabel{tab:cocoqa_results}{{3.4}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Full COCO-QA accuracy per category break-down\relax }}{29}}
\newlabel{tab:cocoqa_acc_breakdown}{{3.5}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces  Example: ``A man is riding a \textbf  {horse}'' $=>$ ``\textbf  {What} is \textbf  {the} man riding?''\relax }}{30}}
\newlabel{fig:whmove}{{3.4}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Counting ability of the image-word model: the outputs are strongly dependent on the types of object asked.\relax }}{31}}
\newlabel{fig:cocoqa_number}{{3.5}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Counting ability of the image-word model: the model outputs ``two'' when it is not certain about the objects.\relax }}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Colour recognition ability of the image-word model: the outputs are strongly dependent on the types of objects described in the question. Even worse, since the questions are the same, the output probability are the same regardless of the images. The output class is consistent with the blind model.\relax }}{32}}
\newlabel{fig:cocoqa_colour}{{3.7}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Object recognition ability of image-word model: when there is less clue from the text, the image-word model seems to ouput better answers. But it still fails on many situations, so the gain is still mainly from language understanding.\relax }}{32}}
\newlabel{fig:cocoqa_object}{{3.8}{32}}
\citation{malinowski14b}
\citation{malinowski14b}
\citation{salton88}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Discussion}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Model selection}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}LSTM sentence model}{33}}
\citation{mikolov13}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Word embedding}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Single direction or bi-direction}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Softmax cross entropy or ranking loss}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Dataset selection}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Visual and semantic knowledge}{35}}
\citation{yosinski14}
\citation{yosinski14}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Future Work}{37}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{future}{{5}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Exploration of current models}{37}}
\citation{xu15}
\citation{simonyan14}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Visual attention model}{38}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Better question generation algorithms}{38}}
\citation{bleu}
\citation{sutskever14}
\citation{kiros14b}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Longer answers and free-form answers}{39}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{41}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{srivastava14}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Neural networks training techniques}{43}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{train_tech}{{A}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Momentum}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Weight regularization}{43}}
\citation{pascanu13}
\citation{zaremba14}
\citation{zaremba14}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Dropout}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Gradient control in training RNNs}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.1}Gradient clipping}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.2}Weight clipping}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {A.5}Dropout in RNNs}{45}}
\citation{simonyan14}
\citation{mikolov13}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Model training details}{47}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Image-word model}{47}}
\newlabel{sec:imgword}{{B.1}{47}}
\citation{simonyan14}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Blind model}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Image-word ranking model}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {B.4}Bidirectional model}{48}}
\newlabel{sec:bimgword}{{B.4}{48}}
\citation{mikolov13}
\bibdata{Reference}
\bibcite{simonyan14}{1}
\bibcite{krizhevsky12}{2}
\bibcite{sutskever14}{3}
\bibcite{kiros14b}{4}
\bibcite{malinowski14b}{5}
\bibcite{mscoco}{6}
\bibcite{ffnn}{7}
\bibcite{cnn}{8}
\bibcite{malinowski14a}{9}
\bibcite{girshick14}{10}
\bibcite{dahl12}{11}
\bibcite{deng13}{12}
\bibcite{mnih07}{13}
\bibcite{mikolov10}{14}
\bibcite{hassoun03}{15}
\bibcite{du2014}{16}
\bibcite{lecun98}{17}
\bibcite{hochreiter97}{18}
\bibcite{mozer95}{19}
\bibcite{zipf49}{20}
\bibcite{bengio03}{21}
\bibcite{mikolov13}{22}
\bibcite{frome13}{23}
\bibcite{weston10}{24}
\bibcite{kulkarni11}{25}
\bibcite{mitchell12}{26}
\bibcite{lewis12}{27}
\bibcite{weston14}{28}
\bibcite{silberman12}{29}
\bibcite{liang13}{30}
\bibcite{bleu}{31}
\bibcite{luong14}{32}
\bibcite{vinyals14}{33}
\bibcite{wu94}{34}
\bibcite{borsley99}{35}
\bibcite{chomsky73}{36}
\bibcite{wordnet}{37}
\bibcite{nltk}{38}
\bibcite{klein03}{39}
\bibcite{ilsvrc14}{40}
\bibcite{salton88}{41}
\bibcite{yosinski14}{42}
\bibcite{xu15}{43}
\bibcite{srivastava14}{44}
\bibcite{pascanu13}{45}
\bibcite{zaremba14}{46}
\bibstyle{ieee}
\newlabel{LastPage}{{}{54}}
