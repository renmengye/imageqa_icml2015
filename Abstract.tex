\chapter*{Abstract}
Computers understanding complex objects in an image and interacting with human through natural language are two open areas of research in computer vision and computational linguistics. A three-year-old child can describe what he/she sees and answer questions regarding to the visual elements, but computers have an extraordinarily hard time handling these simple tasks. Learning and applying visual and semantic knowledge in a computer program will mean a big step in the field of artificial intelligence.

This work, image-based question answering with visual semantic embeddings, aims to let computers jointly learn both vision and natural language through a question-answering (QA) task. In recent years, we have evidenced major breakthroughs in deep learning, machine learning models of deep neural networks, on applications such as object recognition and natural language processing. Inpired by previous approaches using convolutional and recurrent neural networks \cite{simonyan14, krizhevsky12, sutskever14, kiros14b}, we combined these learning architectures to create a common embedding space -- a visual semantic embedding to represent both images and sentences. We designed models that learn to perform question-answering task within this common embedding space.

Image-based question answering is still a fairly new field. We show that our proposed models achieved more than 1.5 times better accuracy compared to the previous effort \cite{malinowski14b} on the same dataset \cite{malinowski14b}. To further evaluate our models and to contribute more data to the research community, we are releasing another dataset that is 20 times larger by converting an image description dataset \cite{mscoco} into question-answer forms. We hope that our work can encourage more follow-up research to achieve better results than ours.

The five chapters will be organized as follows: Chapter 1 will give a brief introduction on the motivation of developing image-based question answering technology. Chapter 2 will cover both the technical backgrounds of our proposed methods, i.e. neural networks and word embeddings, and previous attempts on this very topic. Chapter 3 will explain our neural network medels and our dataset generation algorithms in detail and present the results. Chapter 4 will discuss the significance of our results and Chapter 5 will present some future directions of this research. 